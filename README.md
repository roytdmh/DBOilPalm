ğŸŒ´ Oil Palm Intelligence Scraper (v1 â€“ Category Mirroring Edition)

A modular oil palm web scraping system that:

Crawls reputable agricultural & research sources

Extracts and cleans structured article data

Automatically classifies content into agronomy categories

Stores data in a main SQLite database

Optionally mirrors articles into separate category-specific databases

Allows post-processing splitting of an existing database

ğŸ“¦ Project Files
ScraperScriptOilPalm.py                  # Core scraper (single DB)
ScraperScriptOilPalm_with_mirror.py      # Scraper with per-category DB mirroring
split_sqlite_by_category.py              # Post-processing DB splitter
requirements.txt                         # Python dependencies

ğŸ§  System Overview

The scraper follows this pipeline:

Seed URLs
   â†“
Crawl (reputable domains only)
   â†“
Extract HTML
   â†“
Clean & Normalize Text
   â†“
Keyword-Based Classification
   â†“
Quality Assurance
   â†“
Store in Database

ğŸ—‚ Categories

The scraper classifies content into:

Cultivation

Processing

Environmental Impact

Market Trends

Plantation Management

Uncategorized

Classification is keyword-score based.

ğŸ—„ Database Structure

Main database file:

oilpalmdbmiro.db


Tables created automatically:

pending_urls

visited_urls

articles

Articles table schema:

url TEXT PRIMARY KEY
title TEXT
content TEXT
category TEXT
scraped_date TIMESTAMP
hash TEXT UNIQUE

ğŸš€ Installation
1ï¸âƒ£ Create Virtual Environment (Recommended)
python -m venv venv
venv\Scripts\activate

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


Dependencies:

requests 

requirements

beautifulsoup4 

requirements

lxml 

requirements

langdetect 

requirements

pdfplumber 

requirements

â–¶ Running the Scraper
ğŸ”¹ Option 1 â€” Standard Mode (Single DB Only)
python ScraperScriptOilPalm.py


Behavior:

Stores everything in oilpalmdbmiro.db

No per-category DB files created

ğŸ”¹ Option 2 â€” Mirror Mode (Recommended)
python ScraperScriptOilPalm_with_mirror.py --mirror-category-dbs


Behavior:

Stores data in main DB

Also creates separate DB files:

Cultivation.db
Processing.db
Market_Trends.db
Environmental_Impact.db
Plantation_Management.db
Uncategorized.db


Each contains its own articles table.

ğŸ” Resuming After Interruption

The scraper is fully resumable.

If stopped:

Ctrl + C


Then simply rerun:

python ScraperScriptOilPalm_with_mirror.py --mirror-category-dbs


It will:

Continue from pending_urls

Skip already visited URLs

Prevent duplicate articles (via hash check)

No data loss occurs.

ğŸ›  Splitting an Existing Database

If you already have a populated oilpalmdbmiro.db and want to split it into category-based DB files:

python split_sqlite_by_category.py


Or specify DB path:

python split_sqlite_by_category.py --db "C:\Users\Roy\Documents\DBOilPalmmiro\oilpalmdbmiro.db"


This creates:

CategoryName.db


Rows without a category go to:

Uncategorized.db

ğŸ§ª Quality Assurance Rules

An article is rejected if:

Not English (langdetect)

Duplicate content (hash match)

Domain not in whitelist

Content length < 100 characters

This ensures high data purity.

ğŸ§¯ Safe Restart & Recovery

If system crashes:

Do NOT delete the DB.

Just rerun the script.

Queue resumes automatically.

If DB becomes corrupted:

Restore from backup

Or rerun scraper from scratch

ğŸ“‚ Output Location

Database location (hardcoded in script):

C:\Users\Roy\Documents\DBOilPalmmiro\oilpalmdbmiro.db


Category DBs are created in the same folder.

You may modify DB_PATH inside the script to change this.

âš™ Configuration Points You Can Modify

Inside script:

SEED_URLS â†’ Expand sources

REPUTABLE_DOMAINS â†’ Adjust whitelist

CATEGORIES â†’ Modify classification logic

max_depth in add_to_pending

Politeness delay (time.sleep())

ğŸ§© Architecture Strengths

âœ” Modular
âœ” Resume-safe
âœ” Deduplication built-in
âœ” Domain credibility filtering
âœ” Optional DB mirroring
âœ” Post-processing splitter

ğŸ§­ Typical Workflow
First Time Setup

Run mirror version:

python ScraperScriptOilPalm_with_mirror.py --mirror-category-dbs

Daily Data Expansion

Run again. It will only fetch new URLs.

After Large Crawl

Use:

split_sqlite_by_category.py


if you want physical separation by category.

ğŸ‘¤ Maintainer

Roy Obiri-Yeboah
Oil Palm Data Intelligence System
